{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd59afa-876e-4532-96bf-4277b55b46b2",
   "metadata": {},
   "source": [
    "### TOPIC: Understanding Pooling and Padding in CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e2f52-1b30-4ed1-9055-fe5d1ef99217",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Describe the purpose and benefits of pooling in CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c6683-025e-4430-a748-2a87eb001e7d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3a189-5702-4734-a22f-34f6d4cb8e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pooling is an operation in Convolutional Neural Networks (CNNs) that involves sliding a two-dimensional filter over each channel of a feature \n",
    "map and summarizing the features lying within the region covered by the filter¹. The purpose of pooling is to reduce the dimensions of the \n",
    "feature maps, thus reducing the number of parameters to learn and the amount of computation performed in the network.\n",
    "This makes the model more robust to variations in the position of the features in the input image.\n",
    "\n",
    "There are several benefits to using pooling layers in CNNs. Pooling layers consolidate the features learned by CNNs, gradually shrinking the\n",
    "representation's spatial dimension to minimize the number of parameters and computations in the network³⁴. This can help to make the model \n",
    "stronger in feature extraction. Additionally, pooling can help to decrease the size of the feature maps, making it easier for the model to \n",
    "process and analyze the data.\n",
    "\n",
    "Overall, pooling is an important operation in CNNs that helps to improve the efficiency and effectiveness of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d977e9-6735-44bd-9753-aaae9ed42873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff5cde-d35a-4dbf-86ee-9b7fca662a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Explain the difference between min pooling and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645fcbc-7338-4a19-97f7-d6f90410446b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68e513-574f-4a16-a936-a5760a5e724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Min pooling and max pooling are two types of pooling operations that can be used in Convolutional Neural Networks (CNNs). Both operations \n",
    "involve sliding a two-dimensional filter over each channel of a feature map and summarizing the features lying within the region covered by\n",
    "the filter.\n",
    "\n",
    "The key difference between min pooling and max pooling lies in how the features are summarized. In max pooling, the maximum pixel value of the\n",
    "batch is selected¹. This means that the output of the max pooling operation is the maximum value of all the pixels in the region covered by \n",
    "the filter. Max pooling helps to extract low-level features from the data like edges, points, etc. or if we talk about image processing, \n",
    "max-pooling helps to extract the sharpest features on the image and the sharpest features are a best lower-level representation of the image.\n",
    "\n",
    "On the other hand, in min pooling, the minimum pixel value of the batch is selected¹. This means that the output of the min pooling operation\n",
    "is the minimum value of all the pixels in the region covered by the filter. Min pooling gives better results for images with white background\n",
    "and black object.\n",
    "\n",
    "The choice of which type of pooling operation to use depends on the data at hand and what you want to achieve with your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1e32a-9886-4a4f-9b5c-2d05499c158b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad6f56-771c-417a-8dac-0a7b3c5fe16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Discuss the concept of padding in CNN and its significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2429a-a9fb-4adc-a050-841d91789541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c829fe-5150-4859-9c0e-aca45a967e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Padding is a technique used in Convolutional Neural Networks (CNNs) to preserve the spatial dimensions of the input image after convolution \n",
    "operations on a feature map.\n",
    "During convolution, the size of the output feature map is determined by the size of the input feature map, the size of the kernel, and the\n",
    "stride.\n",
    "If we simply apply the kernel on the input feature map, then the output feature map will be smaller than the input.\n",
    "This can result in the loss of information at the borders of the input feature map. \n",
    "In order to preserve this border information, we use padding.\n",
    "\n",
    "Padding involves adding extra pixels around the border of the input feature map before convolution.\n",
    "This can be done in two ways: Valid Padding and Same Padding.\n",
    "In Valid Padding, no padding is added to the input feature map, and the output feature map is smaller than the input feature map.\n",
    "This is useful when we want to reduce the spatial dimensions of the feature maps.\n",
    "In Same Padding, padding is added to the input feature map such that the size of the output feature map is the same as the input feature map.\n",
    "This is useful when we want to preserve the spatial dimensions of the feature maps.\n",
    "\n",
    "The most common padding value is zero-padding, which involves adding zeros to the borders of the input feature map.\n",
    "Padding can help in reducing the loss of information at the borders of the input feature map and can improve the performance of the model.\n",
    "However, it also increases the computational cost of the convolution operation.\n",
    "\n",
    "Overall, padding is an important technique in CNNs that helps in preserving the spatial dimensions of the feature maps and can improve the \n",
    "performance of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f6a4b-8bf0-4e08-b203-90eb57ce7058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406b631-b481-4cec-8690-cfdc90caa1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Compare and contrast zero-padding and valid-padding in terms oj their effects on the output\n",
    "    feature map size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8bd2a-60a6-4c9c-8bea-b59fd5d8da08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3781cdb-e502-4529-a73b-c0c2a58984ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zero-padding and valid-padding are two types of padding techniques used in Convolutional Neural Networks (CNNs) to preserve the spatial \n",
    "dimensions of the input image after convolution operations on a feature map.\n",
    "\n",
    "In zero-padding, extra pixels with value zero are added around the border of the input feature map before convolution.\n",
    "This can help to preserve the spatial dimensions of the input feature map after convolution.\n",
    "The size of the output feature map is determined by the size of the input feature map, the size of the kernel, and the stride. \n",
    "If we apply zero-padding to the input feature map, then the size of the output feature map will be larger than if we did not apply padding.\n",
    "\n",
    "On the other hand, in valid-padding, no padding is added to the input feature map before convolution.\n",
    "This means that the size of the output feature map will be smaller than the input feature map. \n",
    "Valid-padding can be useful when we want to reduce the spatial dimensions of the feature maps.\n",
    "\n",
    "In summary, zero-padding and valid-padding have different effects on the size of the output feature map. \n",
    "Zero-padding can help to preserve the spatial dimensions of the input feature map after convolution, while valid-padding can help to reduce \n",
    "the spatial dimensions of the feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b0149-068f-4a75-acf5-2cc7ae751a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8314995-56b8-4839-bbc2-533452c45ca7",
   "metadata": {},
   "source": [
    "### TOPIC: Exploring LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e1904-f625-4879-bf23-c503e1c0ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Provide a brief overview of LeNet-5 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c2611-5eab-4db8-9c28-a9d7d1d30f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c25f9-5286-4ac3-b6bc-e07330db041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet-5 is a convolutional neural network architecture that was created by Yann LeCunn in 1998. It is one of the earliest pre-trained models \n",
    "and was used for recognizing handwritten and machine-printed characters. The architecture of LeNet-5 consists of two sets of convolutional \n",
    "and average pooling layers, followed by a flattening convolutional layer, then two fully-connected layers, and finally a softmax classifier.\n",
    "\n",
    "The input to this model is a 32x32 grayscale image. The first convolution operation is applied with a filter size of 5x5 and 6 filters,\n",
    "resulting in a feature map of size 28x28x6. After the first pooling operation, the average pooling is applied, reducing the size of the \n",
    "feature map by half. The network has 5 layers with learnable parameters and hence named LeNet-5.\n",
    "\n",
    "LeNet-5 was popular due to its simple and straightforward architecture. It is a multi-layer convolutional neural network for image \n",
    "classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c126b7-6d33-4928-8280-aef7f875d38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1b548-3e40-4352-b7c1-b9c1739ae783",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Describe the key components of LeNet-5 and their respective purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45184f-8818-4065-93f0-1ae4cdb6b85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6039d-3e48-4833-9583-9dbba3557dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet-5 is a convolutional neural network architecture that was created by Yann LeCunn in 1998. It is one of the earliest pre-trained models \n",
    "and was used for recognizing handwritten and machine-printed characters¹. The architecture of LeNet-5 consists of two sets of convolutional \n",
    "and average pooling layers, followed by a flattening convolutional layer, then two fully-connected layers, and finally a softmax classifier.\n",
    "\n",
    "The key components of LeNet-5 are as follows:\n",
    "    \n",
    "1. Convolutional Layers : These layers apply a set of filters to the input image to extract features such as edges, corners, and objects.\n",
    "2. Average Pooling Layers : These layers perform subsampling by taking the average value of a group of pixels to reduce the dimensions of the\n",
    "   image. This reduces the computational complexity of the image while reducing the dependency of the model on the location of the features \n",
    "    instead of their shape.\n",
    "3. Flattening Convolutional Layer : This layer flattens the output from the previous layer into a one-dimensional vector that can be fed into \n",
    "   the fully-connected layers.\n",
    "4. Fully-Connected Layers : These layers perform classification by taking the output from the previous layer and computing a weighted sum of \n",
    "   the inputs to produce an output vector.\n",
    "5. Softmax Classifier : This layer takes the output from the previous layer and applies the softmax function to produce a probability \n",
    "   distribution over the classes.\n",
    "\n",
    "Overall, LeNet-5 is a simple and straightforward architecture that utilizes multiple types of layers to extract features from images and \n",
    "perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d8c11d-89d7-4b78-9ecc-079069a94c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed32a4b-b378-4870-bcf9-c35a3d9d5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Discuss the advantages and limitations of LeNet-5 in the context of image classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48e725-002b-4419-91df-8327fcd2db35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bced4-ed32-4e8f-8e1e-d8eb125b53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet-5 is a convolutional neural network architecture that was created by Yann LeCunn in 1998². It is one of the earliest pre-trained models \n",
    "and was used for recognizing handwritten and machine-printed characters. The architecture of LeNet-5 consists of two sets of convolutional\n",
    "and average pooling layers, followed by a flattening convolutional layer, then two fully-connected layers, and finally a softmax classifier.\n",
    "\n",
    "In the context of image classification tasks, LeNet-5 has several advantages. It is a simple and straightforward architecture that utilizes\n",
    "multiple types of layers to extract features from images and perform classification. The model is able to learn low-level features such as\n",
    "edges and corners, as well as high-level features such as objects. This makes it well-suited for image classification tasks.\n",
    "\n",
    "However, LeNet-5 also has some limitations. The model was primarily designed for handwritten digit recognition tasks and may not perform as \n",
    "well on other types of image classification tasks. Additionally, the architecture of LeNet-5 is relatively simple compared to more modern \n",
    "convolutional neural network architectures, which may limit its performance on more complex image classification tasks.\n",
    "\n",
    "Overall, LeNet-5 is a classic convolutional neural network architecture that has played a significant role in advancing the field of deep \n",
    "learning. While it has some limitations, it remains an important model for image classification tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e92d58-408e-4512-be63-cb10e08e8cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d82e2da-199c-4865-a059-f0816d0a3ed6",
   "metadata": {},
   "source": [
    "### TOPIC: Analyzing AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeafa7e-3d6a-4cc3-b46d-f52cf6b4d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Present an overview of the AlexNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e0468-3c35-4201-a17e-7f82f7f92dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4445cd-870f-44ff-bee7-397b6ed6f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet is a convolutional neural network (CNN) architecture designed by Alex Krizhevsky in collaboration with Ilya Sutskever and Geoffrey \n",
    "Hinton. It competed in the ImageNet Large Scale Visual Recognition Challenge on September 30, 2012, and achieved a top-5 error of 15.3%,\n",
    "more than 10.8 percentage points lower than that of the runner-up.\n",
    "\n",
    "The architecture of AlexNet consists of eight layers with learnable parameters. The first five layers are convolutional layers, some of which\n",
    "are followed by max-pooling layers, and the last three are fully connected layers. The model uses ReLU activation in each of these layers \n",
    "except the output layer.\n",
    "The authors found that using ReLU as an activation function accelerated the speed of the training process by almost six times.\n",
    "They also used dropout layers to prevent their model from overfitting.\n",
    "\n",
    "AlexNet's architecture, with its innovative use of convolutional layers and rectified linear units (ReLU), laid the foundation for modern deep\n",
    "learning models, advancing computer vision and pattern recognition applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a087a43-f424-45b1-b593-63a2746ae9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbdb6b6-10bf-46be-be67-9b4f7a8ec316",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Explain the architectural innovations introduced in AlexNet that contributed to its breakthrough\n",
    "performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113453ec-6f0d-4cad-8253-4c4be773e213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e42582-257b-4197-bb13-fed16825e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet introduced several architectural innovations that contributed to its breakthrough performance in the ImageNet Large Scale Visual \n",
    "Recognition Challenge (ILSVRC) in 2012. Some of these innovations include:\n",
    "\n",
    "1. Increased depth : AlexNet increased the depth of the network compared to previous architectures such as LeNet-5. The model consists of eight\n",
    "   layers with learnable parameters, including five convolutional layers and three fully connected layers.\n",
    "\n",
    "2. Rectified Linear Units (ReLU) : AlexNet used ReLU as the activation function in each layer except the output layer. The authors found that\n",
    "   using ReLU accelerated the speed of the training process by almost six times compared to traditional activation functions such as sigmoid \n",
    "    or tanh.\n",
    "\n",
    "3. Dropout : AlexNet used dropout layers to prevent overfitting during training. Dropout randomly sets a fraction of the neurons in a layer to\n",
    "   zero during each forward pass, which helps to regularize the model and prevent overfitting.\n",
    "\n",
    "4. Data augmentation : AlexNet used data augmentation techniques such as image translations, horizontal reflections, and altering the \n",
    "   intensities of the RGB channels to artificially increase the size of the training dataset¹. This helped to reduce overfitting and improve\n",
    "    generalization.\n",
    "\n",
    "These architectural innovations, along with others such as using multiple GPUs for training, helped AlexNet achieve a top-5 error rate\n",
    "of 15.3% in the ILSVRC 2012 competition, more than 10.8 percentage points lower than that of the runner-up. \n",
    "AlexNet's architecture laid the foundation for modern deep learning models and advanced computer vision and pattern recognition applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39d563-c4be-4f61-af41-e16ba816e0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8bb2cc-45e0-490d-a8a0-ec5dba25f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Discuss the role of convolutional layers, pooling layers, and fully connected layers in AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df1146-428f-4ce7-b756-fb0b0f1e46fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61f1f0-bb85-47fe-b23b-43017ac4f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "In AlexNet, convolutional layers, pooling layers, and fully connected layers play different roles in processing the input image and making a\n",
    "final prediction.\n",
    "\n",
    "1. Convolutional layers : The first five layers of AlexNet are convolutional layers. These layers apply filters to the input image to extract \n",
    "  features such as edges, corners, and objects⁴. Each convolutional layer consists of convolutional filters and a nonlinear activation functio \n",
    "    ReLU.The filters are learned during training through backpropagation and gradient descent.\n",
    "\n",
    "2. Pooling layers : AlexNet has three max-pooling layers that follow some of the convolutional layers. These layers downsample the image by \n",
    "   taking the maximum value over a small region, reducing the spatial dimensions of the feature map. This helps to reduce computation and also\n",
    "    makes the model more robust to small translations in the input image.\n",
    "\n",
    "3. Fully connected layers : The last three layers of AlexNet are fully connected layers. These layers take the output from the previous layer\n",
    "   and compute a weighted sum of the inputs, followed by an activation function. The final fully connected layer produces the final output\n",
    "    classifications of the network.\n",
    "\n",
    "In summary, convolutional layers extract features from the input image, pooling layers downsample the image to reduce computation, and fully\n",
    "connected layers make the final prediction. The network learns the optimal filters and weights through backpropagation and gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44751ec6-3758-4409-ac7d-95bcbced0d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
